{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec56fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a03ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677e62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.ImageFolder(\"D:\\\\si\\\\Faces for Training\\\\Faces for Training\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4201735",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c990d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Conv2d(1,96,(11,11)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(96,256,(5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(256,384,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Linear(384,1024),\n",
    "            nn.Linear(1024,128)\n",
    "        )\n",
    "    def run(self,x):\n",
    "        o=self.model(x)\n",
    "        return o\n",
    "    def forward(self,x1,x2):\n",
    "        o1=run(x1)\n",
    "        o2=run(x2)\n",
    "        return o1,o2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d0a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=siamese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5201f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        super().__init__()\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "\n",
    "       \n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "\n",
    "            while True:\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([int(img1_tuple[1] != img0_tuple[1])], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7add5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata=SiameseNetworkDataset(data,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25adebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=DataLoader(sdata,8,shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e84c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "       \n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2684d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = siamese().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "\n",
    "    for i, (img0, img1, label) in enumerate(data_loader, 0):\n",
    "\n",
    "       \n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        output1, output2 = net(img0, img1)\n",
    "\n",
    "        \n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "       \n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
